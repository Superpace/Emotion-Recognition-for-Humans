{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_bqLssF1uIaI",
    "outputId": "65b48de5-0231-4c9f-9701-c899887e385a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting noisereduce\n",
      "  Downloading https://files.pythonhosted.org/packages/04/d0/4e50cac3daaa1522a3730ec22750ca86f6c221a480e65c8d6b0ab18a21ed/noisereduce-1.1.0.tar.gz\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from noisereduce) (1.4.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from noisereduce) (3.2.2)\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (from noisereduce) (0.8.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from noisereduce) (1.19.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from noisereduce) (4.41.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->noisereduce) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->noisereduce) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->noisereduce) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->noisereduce) (1.3.1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa->noisereduce) (0.2.2)\n",
      "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa->noisereduce) (1.4.0)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa->noisereduce) (0.10.3.post1)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa->noisereduce) (0.22.2.post1)\n",
      "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa->noisereduce) (0.51.2)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->noisereduce) (2.1.9)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa->noisereduce) (4.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa->noisereduce) (20.9)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa->noisereduce) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->noisereduce) (1.15.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa->noisereduce) (2.23.0)\n",
      "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa->noisereduce) (1.4.4)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa->noisereduce) (1.14.5)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa->noisereduce) (0.34.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa->noisereduce) (57.0.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa->noisereduce) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa->noisereduce) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa->noisereduce) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa->noisereduce) (2021.5.30)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa->noisereduce) (2.20)\n",
      "Building wheels for collected packages: noisereduce\n",
      "  Building wheel for noisereduce (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for noisereduce: filename=noisereduce-1.1.0-cp37-none-any.whl size=7610 sha256=fd7aa780b852dbbda7656186fc3ab1bb25c59d9f55e1b374ddb0449eed54cc96\n",
      "  Stored in directory: /root/.cache/pip/wheels/a6/2c/70/f9ccb41280dcfbe3eaeb7930f913dd85394617f3d3136f29cc\n",
      "Successfully built noisereduce\n",
      "Installing collected packages: noisereduce\n",
      "Successfully installed noisereduce-1.1.0\n",
      "Collecting pyswarms\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/fd/5c2baba82425b75baf7dbec5af57219cd252aa8a1ace4f5cd1d88e472276/pyswarms-1.3.0-py2.py3-none-any.whl (104kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 29.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from pyswarms) (3.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyswarms) (1.4.1)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyswarms) (0.16.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from pyswarms) (3.13)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pyswarms) (4.41.1)\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from pyswarms) (21.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyswarms) (1.19.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.3.1->pyswarms) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.3.1->pyswarms) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.3.1->pyswarms) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.3.1->pyswarms) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=1.3.1->pyswarms) (1.15.0)\n",
      "Installing collected packages: pyswarms\n",
      "Successfully installed pyswarms-1.3.0\n",
      "Collecting keras-adabound\n",
      "  Downloading https://files.pythonhosted.org/packages/bf/74/85de8379eba8e0f819ef9b62ff32d24a3f624758800e12bd9572e3afb546/keras-adabound-0.6.0.tar.gz\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-adabound) (1.19.5)\n",
      "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (from keras-adabound) (2.4.3)\n",
      "Requirement already satisfied: typeguard in /usr/local/lib/python3.7/dist-packages (from keras-adabound) (2.7.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras->keras-adabound) (3.13)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras->keras-adabound) (1.4.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras->keras-adabound) (3.1.0)\n",
      "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->Keras->keras-adabound) (1.5.2)\n",
      "Building wheels for collected packages: keras-adabound\n",
      "  Building wheel for keras-adabound (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for keras-adabound: filename=keras_adabound-0.6.0-cp37-none-any.whl size=6610 sha256=51cc98c7f2d7922fedb76f8260b9cf148385dc075439ea006538f44ac8765030\n",
      "  Stored in directory: /root/.cache/pip/wheels/f1/81/9c/04af926d62bddd280c97af1704a9baaef511664b56865958e8\n",
      "Successfully built keras-adabound\n",
      "Installing collected packages: keras-adabound\n",
      "Successfully installed keras-adabound-0.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/noisereduce/noisereduce.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import math \n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile\n",
    "import os, glob , pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "!pip install noisereduce\n",
    "!pip install pyswarms\n",
    "!pip install keras-adabound\n",
    "\n",
    "from keras_adabound import AdaBound\n",
    "\n",
    "import noisereduce as nr\n",
    "import pyswarms as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lk-Jawgvuxq-",
    "outputId": "3a051883-a96c-40cf-ca2e-89658f8975db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive',force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RNFNO7dNuIaS"
   },
   "outputs": [],
   "source": [
    "#Tüm Duyguları bir dictionary'e aktardık\n",
    "emotions={\n",
    "  0:'Normal',\n",
    "  1:'Sakin',\n",
    "  2:'Mutlu',\n",
    "  3:'Üzgün',\n",
    "  4:'Sinirli',\n",
    "  5:'Korkulu',\n",
    "  6:'İğrenme',\n",
    "  7:'Şaşırma'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EnJngOoVuIaX"
   },
   "outputs": [],
   "source": [
    "def extract_features(file_name, noisy):\n",
    "    audio_duration = 3\n",
    "    sample_rate = 22050\n",
    "\n",
    "    y, sr = librosa.load(os.path.join(file_name),res_type='kaiser_fast')\n",
    "    \n",
    "    if noisy:\n",
    "        y = nr.reduce_noise(audio_clip=y, noise_clip=y)\n",
    "\n",
    "    mfcc=np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40,fmin=30,fmax=2700).T,axis=0)\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2cF_C2fyuIaW"
   },
   "outputs": [],
   "source": [
    "x,y = [],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bMVdde8i0uB5"
   },
   "outputs": [],
   "source": [
    "def load_data(test_size=0.2):\n",
    "    global x,y\n",
    "    x,y=[],[]\n",
    "    print(\"Ravdess Datas Loading ...\")\n",
    "    for file in tqdm(glob.glob('/content/drive/MyDrive/Colab Notebooks/RAVDESS/Audio_Speech_Actors_01-24/Actor_*/*.wav')):\n",
    "        feature=\"\"\n",
    "        file_name=os.path.basename(file)\n",
    "        \n",
    "        emotion=int(file_name.split(\"-\")[2])-1\n",
    "        feature=extract_features(file,noisy=False)\n",
    "\n",
    "        x.append(feature)\n",
    "        y.append(emotion)\n",
    "    return train_test_split(np.array(x), np.array(y), test_size=test_size, train_size= 1-test_size,random_state=42,shuffle=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355,
     "referenced_widgets": [
      "d153754947f0471391e6be012b07c703",
      "9e0688ef13f745f7ad1bf027ddfed2de",
      "d292c824d8c74fbdac065af0a18f6a7b",
      "9ceb6e7edec9463ab6192d10902c5c7b",
      "4a2e806b1a5243b0af361778732f137c",
      "cf80a04fdda34d62a507291fa84a521e",
      "6eab77adf1f542ab9c22d76a63251f33",
      "83ad67d5c119441dbedf53f234bebdf5"
     ]
    },
    "id": "8zQxha1WuIaY",
    "outputId": "8b30f91e-65b6-4783-faf9-b6f4906d8992",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ravdess Datas Loading ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d153754947f0471391e6be012b07c703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5252.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-293528c55123>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-65ff1cc91666>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(test_size)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0memotion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mfeature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnoisy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-70a21c8f4d4c>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(file_name, noisy)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msample_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m22050\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kaiser_fast'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnoisy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    627\u001b[0m         self._info = _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    628\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0;31m# Move write position to 0 (like in Python file objects)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m                     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfilesystemencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m             \u001b[0mfile_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopenfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m             \u001b[0mfile_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_open_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=load_data(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U6Vd8dituIaa",
    "outputId": "77669c41-dac7-481d-b6b0-5bd989756dc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5252, 40)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "temp = list(zip(x, y))\n",
    "random.shuffle(temp)\n",
    "x, y = zip(*temp)\n",
    "x = np.array(x)\n",
    "print(x.shape)\n",
    "\n",
    "#mean = np.mean(x_train, axis=0)\n",
    "#std = np.std(x_train, axis=0)\n",
    "\n",
    "\n",
    "#X_train = (x_train - mean)/std\n",
    "#X_test = (x_test - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F63L8Hy5_WJL",
    "outputId": "1838ca9a-1981-4f66-cab3-3ee176220c9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/content/drive/MyDrive/Colab Notebooks/FeaturesLabels/Y.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(x, os.path.join(\"/content/drive/MyDrive/Colab Notebooks/FeaturesLabels\", \"X.joblib\"))\n",
    "joblib.dump(y, os.path.join(\"/content/drive/MyDrive/Colab Notebooks/FeaturesLabels\", \"Y.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SNR-hMqEhXa_"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "x = joblib.load('/content/drive/MyDrive/Colab Notebooks/FeaturesLabels/X.joblib')\n",
    "y = joblib.load('/content/drive/MyDrive/Colab Notebooks/FeaturesLabels/Y.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "49Y8QUj0q0jD"
   },
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "x_train,x_test,y_train,y_test = train_test_split(np.array(x), np.array(y), test_size=test_size, train_size= 1-test_size,random_state=42,shuffle=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PK-jMJJmrMGX",
    "outputId": "b43be04d-de93-405a-9ab1-847912031f13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4201, 40)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CzI5J8mruIad"
   },
   "source": [
    "## Decision Tree\n",
    "### -Parametresiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0UiXG1ukuIad",
    "outputId": "368fcb79-5e58-4fcc-ea52-3eb11fe7715c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.698382492863939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6986775653080882, 0.698382492863939, 0.6978077423985058, None)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "modelDT = DecisionTreeClassifier()\n",
    "modelDT.fit(x_train,y_train)\n",
    "y_pred = modelDT.predict(x_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "precision_recall_fscore_support(y_test,y_pred,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzQq_BZuuIae"
   },
   "source": [
    "## KNN ve GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0tKk1SHxuIaf",
    "outputId": "d437198c-acff-4a49-af25-49b74e2f582a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:   53.5s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'algorithm': ['auto'], 'leaf_size': [2],\n",
       "                         'metric': ['manhattan'],\n",
       "                         'n_neighbors': [10, 20, 30, 40, 50, 60, 70, 80, 90],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 161,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sonrasında KNN algoritmasını GridSearchCV ile taratarak\n",
    "# algoritma için en iyi parametreleri araştırdık\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Aranacak ve diğerleri ile kombinlenecek olan \n",
    "# Hiper parametreleri bir sözlük(dict) veri tipine aktardık \n",
    "grid_params = {\n",
    "    'n_neighbors': [x for x in range(10,100,10)],\n",
    "    'weights': ['uniform','distance'],\n",
    "    'algorithm': ['auto'],\n",
    "    'leaf_size': [2],\n",
    "    'metric': ['manhattan']\n",
    "}\n",
    "\n",
    "# KNN modelimizi GridSearchCV ile oluşturduk ve parametreleri ekledik\n",
    "modelKNN = GridSearchCV(KNeighborsClassifier(), grid_params, cv=10, n_jobs=-1,verbose=2)\n",
    "modelKNN.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fOuTotpUuIah"
   },
   "outputs": [],
   "source": [
    "# GridSearchCV bizim için sözlüğümüzdeki\n",
    "# en uygun KNN parametrelerini buldu\n",
    "print(modelKNN.best_score_)\n",
    "print(modelKNN.best_estimator_)\n",
    "print(modelKNN.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYv2E_ZmuIai"
   },
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uDcGtHkruIai",
    "outputId": "2b810cc1-5854-47f0-c973-eb27443d21f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8106565176022835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8125310041967058, 0.8106565176022835, 0.8100928034628097, None)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelKNN = KNeighborsClassifier(algorithm='auto', leaf_size=2, metric='manhattan',\n",
    "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
    "                     weights='distance')\n",
    "modelKNN.fit(x_train,y_train)\n",
    "\n",
    "y_pred = modelKNN.predict(x_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "precision_recall_fscore_support(y_test,y_pred,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7D1XhRTMuIaj"
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3rMHukxN219-",
    "outputId": "419beb6f-cc6b-4d59-a045-5933d719d967"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.709, total=   2.5s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.675, total=   2.5s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    5.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.665, total=   2.5s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.688, total=   2.5s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.690, total=   2.5s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.688, total=   2.5s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.695, total=   2.4s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.686, total=   2.5s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.682, total=   2.5s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.690, total=   2.5s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.658, total=   1.9s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.652, total=   1.8s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.613, total=   1.9s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.651, total=   1.9s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.651, total=   1.9s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.663, total=   1.9s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.661, total=   1.9s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.636, total=   1.9s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.659, total=   1.9s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.661, total=   1.9s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.850, total=   1.9s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.816, total=   1.9s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.796, total=   1.9s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.838, total=   1.9s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.829, total=   1.9s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.819, total=   1.9s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.815, total=   1.9s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.811, total=   1.9s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.802, total=   1.9s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.840, total=   1.9s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.772, total=   1.3s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.759, total=   1.3s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.735, total=   1.3s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.792, total=   1.3s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.766, total=   1.3s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.770, total=   1.3s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.775, total=   1.3s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.745, total=   1.3s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.768, total=   1.2s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.758, total=   1.3s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.882, total=   2.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.844, total=   1.9s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.840, total=   1.9s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.891, total=   2.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.865, total=   2.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.846, total=   2.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.869, total=   1.9s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.865, total=   2.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.859, total=   2.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.886, total=   2.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.835, total=   1.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.816, total=   1.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.794, total=   1.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.838, total=   1.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.836, total=   1.1s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.808, total=   1.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.829, total=   1.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.810, total=   1.1s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.829, total=   1.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.840, total=   1.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.884, total=   2.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.840, total=   1.9s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.840, total=   2.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.891, total=   2.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.861, total=   2.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.853, total=   2.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.874, total=   2.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.863, total=   2.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.855, total=   2.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.886, total=   2.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.905, total=   1.1s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.819, total=   1.1s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.827, total=   1.1s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.857, total=   1.1s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.874, total=   1.1s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.838, total=   1.1s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.865, total=   1.1s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.848, total=   1.1s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.821, total=   1.1s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.872, total=   1.1s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.884, total=   2.1s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.840, total=   2.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.840, total=   2.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.891, total=   2.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.861, total=   2.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.853, total=   2.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.874, total=   2.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.863, total=   2.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.855, total=   2.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.886, total=   2.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.876, total=   1.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.804, total=   1.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.821, total=   1.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.859, total=   1.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.863, total=   1.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.838, total=   1.4s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.863, total=   1.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.853, total=   1.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.838, total=   1.3s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.859, total=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000], 'gamma': [0.001, 0.0001],\n",
       "                         'kernel': ['rbf']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 170,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [0.001, 0.0001],\n",
    "              'kernel': ['rbf']} \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3,cv=10)\n",
    "grid.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GOUER-R73Lnw"
   },
   "outputs": [],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cTp0oJTnuIaj",
    "outputId": "59fbcbbb-3d44-4136-88a7-582a1f3f0010"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8553758325404377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8566405126421588, 0.8553758325404377, 0.8555071520669754, None)"
      ]
     },
     "execution_count": 95,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svclassifier = SVC(gamma = 0.001 ,C = 100,kernel='rbf')\n",
    "svclassifier.fit(x_train,y_train)\n",
    "y_pred = svclassifier.predict(x_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "precision_recall_fscore_support(y_test,y_pred,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWCC22luuIak"
   },
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JASCmjfA6t35",
    "outputId": "25f3d347-0e82-4833-f3f4-4c9067deb6a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (2000,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
      "0.8388451532632054\n"
     ]
    }
   ],
   "source": [
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(200,),(500,),(1000,),(2000,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.05],\n",
    "    'learning_rate': ['adaptive'],\n",
    "}\n",
    "\n",
    "mlp_gs = MLPClassifier(max_iter=2000)\n",
    "\n",
    "clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=-1, cv=10)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D3pdH9_R7ED5",
    "outputId": "38ba5415-8071-4121-96e3-f8e19e40db4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (2000,), 'learning_rate': 'adaptive', 'solver': 'adam'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8388451532632054"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(clf.best_params_)\n",
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BT-Bgn_CuIak",
    "outputId": "c89edadd-dc80-43d6-93c7-464ae6ba78d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7145575642245481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7686000206505497, 0.7459562321598477, 0.7494984575859066, None)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelMLP=MLPClassifier(hidden_layer_sizes=(2000,), learning_rate='adaptive', max_iter=2000,activation='tanh',alpha=0.05,solver='adam')\n",
    "\n",
    "modelMLP.fit(x_train,y_train)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "y_pred = modelMLP.predict(x_test)\n",
    "precision_recall_fscore_support(y_test,y_pred,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wi_aaX7CuIal"
   },
   "outputs": [],
   "source": [
    "# Burada hangi duyguların hangi başarı skorlarına sahip olduklarını\n",
    "# Yani modelimizin hangi duygularda daha başarılı olduğunu anlıyoruz\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVVW2KlOuIao"
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VutANNrQLFUk",
    "outputId": "d26e5387-3eee-4d4b-a7af-c2d1ba2d2224"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [20, 140, 260, 380, 500], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 43, 76, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 20, stop = 500, num = 5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 4)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VHwn3MsaLM7Y",
    "outputId": "cbacd499-fc5d-4809-ae8f-0d6ebe3eabd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score=nan,\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    max_samples=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=100,\n",
       "                                                    n_job...\n",
       "                                                    random_state=42, verbose=0,\n",
       "                                                    warm_start=False),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [10, 43, 76, 110, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [20, 140, 260, 380,\n",
       "                                                         500]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 200,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 10, cv = 10, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JKD9JuzYPyZZ",
    "outputId": "7dbd2ad0-d957-4e3c-b77e-d3813ceba34a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 260, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None}\n",
      "0.8389176172370089\n"
     ]
    }
   ],
   "source": [
    "print(rf_random.best_params_)\n",
    "print(rf_random.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mkn-Lor5uIap",
    "outputId": "87f91733-3fbb-4c91-fa1b-5bbc20eab402"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8372978116079924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8473228501692681, 0.8372978116079924, 0.8384170949266735, None)"
      ]
     },
     "execution_count": 96,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRF = RandomForestClassifier(n_estimators = 260,min_samples_split=2,min_samples_leaf=1,max_features=\"sqrt\",max_depth=None,random_state=42)\n",
    "modelRF.fit(x_train,y_train)\n",
    "y_pred = modelRF.predict(x_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "precision_recall_fscore_support(y_test,y_pred,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derin Öğrenme Teknikleri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DnKgwU1_uIaq",
    "outputId": "1929400e-8932-4a34-f90a-2bf1d26335a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Yeni boyutlarımız aşağıdaki gibidir \n",
    "x_traincnn = np.expand_dims(x_train , axis = 2)\n",
    "x_testcnn = np.expand_dims(x_test , axis = 2)\n",
    "\n",
    "x_traincnn.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0RfjENZ3uIaq"
   },
   "outputs": [],
   "source": [
    "# CNN için gerekli olan keras kütüphanesinden\n",
    "# ihtiyacımız olanları projemize dahil ediyoruz\n",
    "import keras\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D,MaxPooling1D,AveragePooling1D,Dense,BatchNormalization\n",
    "from keras.layers import Flatten,Dropout,Activation,LSTM,TimeDistributed,ReLU\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras import optimizers\n",
    "from keras.callbacks import  History, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ku8bEdsZt2tx",
    "outputId": "e37c0a7c-888a-4b16-98c8-14eee1efe753"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "132/132 [==============================] - 5s 16ms/step - loss: 2.0839 - accuracy: 0.1160 - val_loss: 2.0623 - val_accuracy: 0.1323\n",
      "Epoch 2/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 2.0504 - accuracy: 0.1640 - val_loss: 2.0409 - val_accuracy: 0.1551\n",
      "Epoch 3/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 2.0261 - accuracy: 0.1895 - val_loss: 2.0222 - val_accuracy: 0.1694\n",
      "Epoch 4/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 2.0057 - accuracy: 0.2028 - val_loss: 2.0027 - val_accuracy: 0.1931\n",
      "Epoch 5/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.9767 - accuracy: 0.2301 - val_loss: 1.9812 - val_accuracy: 0.2293\n",
      "Epoch 6/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.9509 - accuracy: 0.2528 - val_loss: 1.9549 - val_accuracy: 0.2464\n",
      "Epoch 7/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.9172 - accuracy: 0.2816 - val_loss: 1.9234 - val_accuracy: 0.2674\n",
      "Epoch 8/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.8754 - accuracy: 0.3143 - val_loss: 1.8873 - val_accuracy: 0.2864\n",
      "Epoch 9/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.8447 - accuracy: 0.3275 - val_loss: 1.8506 - val_accuracy: 0.3045\n",
      "Epoch 10/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.7964 - accuracy: 0.3381 - val_loss: 1.8176 - val_accuracy: 0.3197\n",
      "Epoch 11/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.7397 - accuracy: 0.3728 - val_loss: 1.7880 - val_accuracy: 0.3511\n",
      "Epoch 12/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 1.7115 - accuracy: 0.3930 - val_loss: 1.7610 - val_accuracy: 0.3815\n",
      "Epoch 13/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 1.6941 - accuracy: 0.4085 - val_loss: 1.7346 - val_accuracy: 0.3977\n",
      "Epoch 14/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.6536 - accuracy: 0.4332 - val_loss: 1.7110 - val_accuracy: 0.4091\n",
      "Epoch 15/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.6322 - accuracy: 0.4259 - val_loss: 1.6888 - val_accuracy: 0.4120\n",
      "Epoch 16/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.6005 - accuracy: 0.4439 - val_loss: 1.6703 - val_accuracy: 0.4101\n",
      "Epoch 17/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 1.5854 - accuracy: 0.4487 - val_loss: 1.6529 - val_accuracy: 0.4120\n",
      "Epoch 18/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.5773 - accuracy: 0.4502 - val_loss: 1.6399 - val_accuracy: 0.4186\n",
      "Epoch 19/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.5527 - accuracy: 0.4481 - val_loss: 1.6247 - val_accuracy: 0.4225\n",
      "Epoch 20/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.5311 - accuracy: 0.4574 - val_loss: 1.6128 - val_accuracy: 0.4253\n",
      "Epoch 21/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.5304 - accuracy: 0.4551 - val_loss: 1.5995 - val_accuracy: 0.4396\n",
      "Epoch 22/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.5151 - accuracy: 0.4641 - val_loss: 1.5867 - val_accuracy: 0.4396\n",
      "Epoch 23/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.4830 - accuracy: 0.4807 - val_loss: 1.5757 - val_accuracy: 0.4405\n",
      "Epoch 24/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.4901 - accuracy: 0.4656 - val_loss: 1.5629 - val_accuracy: 0.4520\n",
      "Epoch 25/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.4769 - accuracy: 0.4846 - val_loss: 1.5518 - val_accuracy: 0.4539\n",
      "Epoch 26/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.4536 - accuracy: 0.4909 - val_loss: 1.5383 - val_accuracy: 0.4548\n",
      "Epoch 27/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.4358 - accuracy: 0.4940 - val_loss: 1.5244 - val_accuracy: 0.4634\n",
      "Epoch 28/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.4390 - accuracy: 0.5014 - val_loss: 1.5115 - val_accuracy: 0.4643\n",
      "Epoch 29/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.4194 - accuracy: 0.5057 - val_loss: 1.4994 - val_accuracy: 0.4700\n",
      "Epoch 30/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.4059 - accuracy: 0.5058 - val_loss: 1.4897 - val_accuracy: 0.4672\n",
      "Epoch 31/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.3916 - accuracy: 0.5106 - val_loss: 1.4721 - val_accuracy: 0.4738\n",
      "Epoch 32/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.3846 - accuracy: 0.5291 - val_loss: 1.4601 - val_accuracy: 0.4814\n",
      "Epoch 33/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.3715 - accuracy: 0.5208 - val_loss: 1.4452 - val_accuracy: 0.4833\n",
      "Epoch 34/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.3403 - accuracy: 0.5281 - val_loss: 1.4310 - val_accuracy: 0.4853\n",
      "Epoch 35/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.3446 - accuracy: 0.5213 - val_loss: 1.4192 - val_accuracy: 0.4872\n",
      "Epoch 36/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.3440 - accuracy: 0.5227 - val_loss: 1.4023 - val_accuracy: 0.4929\n",
      "Epoch 37/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.2958 - accuracy: 0.5459 - val_loss: 1.3857 - val_accuracy: 0.4976\n",
      "Epoch 38/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.2743 - accuracy: 0.5513 - val_loss: 1.3725 - val_accuracy: 0.5014\n",
      "Epoch 39/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.2859 - accuracy: 0.5411 - val_loss: 1.3583 - val_accuracy: 0.5033\n",
      "Epoch 40/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.2701 - accuracy: 0.5548 - val_loss: 1.3414 - val_accuracy: 0.5100\n",
      "Epoch 41/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.2488 - accuracy: 0.5557 - val_loss: 1.3279 - val_accuracy: 0.5157\n",
      "Epoch 42/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.2320 - accuracy: 0.5631 - val_loss: 1.3105 - val_accuracy: 0.5262\n",
      "Epoch 43/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.2263 - accuracy: 0.5640 - val_loss: 1.3007 - val_accuracy: 0.5271\n",
      "Epoch 44/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.2050 - accuracy: 0.5684 - val_loss: 1.2827 - val_accuracy: 0.5309\n",
      "Epoch 45/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.1777 - accuracy: 0.5873 - val_loss: 1.2718 - val_accuracy: 0.5338\n",
      "Epoch 46/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.1789 - accuracy: 0.5736 - val_loss: 1.2576 - val_accuracy: 0.5452\n",
      "Epoch 47/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.1880 - accuracy: 0.5769 - val_loss: 1.2398 - val_accuracy: 0.5519\n",
      "Epoch 48/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.1659 - accuracy: 0.5927 - val_loss: 1.2290 - val_accuracy: 0.5604\n",
      "Epoch 49/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.1352 - accuracy: 0.5921 - val_loss: 1.2160 - val_accuracy: 0.5642\n",
      "Epoch 50/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.1176 - accuracy: 0.5971 - val_loss: 1.2040 - val_accuracy: 0.5699\n",
      "Epoch 51/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.1115 - accuracy: 0.6016 - val_loss: 1.1888 - val_accuracy: 0.5652\n",
      "Epoch 52/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.1237 - accuracy: 0.6060 - val_loss: 1.1739 - val_accuracy: 0.5747\n",
      "Epoch 53/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.0871 - accuracy: 0.6060 - val_loss: 1.1651 - val_accuracy: 0.5737\n",
      "Epoch 54/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.0916 - accuracy: 0.6081 - val_loss: 1.1584 - val_accuracy: 0.5728\n",
      "Epoch 55/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.0731 - accuracy: 0.6094 - val_loss: 1.1480 - val_accuracy: 0.5785\n",
      "Epoch 56/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.0458 - accuracy: 0.6247 - val_loss: 1.1375 - val_accuracy: 0.5871\n",
      "Epoch 57/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 1.0682 - accuracy: 0.6135 - val_loss: 1.1314 - val_accuracy: 0.5766\n",
      "Epoch 58/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.0504 - accuracy: 0.6188 - val_loss: 1.1221 - val_accuracy: 0.5947\n",
      "Epoch 59/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.0591 - accuracy: 0.6190 - val_loss: 1.1138 - val_accuracy: 0.5966\n",
      "Epoch 60/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.0336 - accuracy: 0.6298 - val_loss: 1.1080 - val_accuracy: 0.5985\n",
      "Epoch 61/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 1.0205 - accuracy: 0.6346 - val_loss: 1.0999 - val_accuracy: 0.5994\n",
      "Epoch 62/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 1.0244 - accuracy: 0.6310 - val_loss: 1.0978 - val_accuracy: 0.5947\n",
      "Epoch 63/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.0254 - accuracy: 0.6215 - val_loss: 1.0940 - val_accuracy: 0.5966\n",
      "Epoch 64/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 1.0046 - accuracy: 0.6258 - val_loss: 1.0831 - val_accuracy: 0.5985\n",
      "Epoch 65/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.9902 - accuracy: 0.6315 - val_loss: 1.0772 - val_accuracy: 0.6032\n",
      "Epoch 66/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 1.0014 - accuracy: 0.6318 - val_loss: 1.0723 - val_accuracy: 0.6023\n",
      "Epoch 67/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.9885 - accuracy: 0.6332 - val_loss: 1.0869 - val_accuracy: 0.5947\n",
      "Epoch 68/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.9688 - accuracy: 0.6475 - val_loss: 1.0656 - val_accuracy: 0.6099\n",
      "Epoch 69/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.9841 - accuracy: 0.6408 - val_loss: 1.0569 - val_accuracy: 0.6070\n",
      "Epoch 70/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.9808 - accuracy: 0.6407 - val_loss: 1.0605 - val_accuracy: 0.6166\n",
      "Epoch 71/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.9571 - accuracy: 0.6516 - val_loss: 1.0516 - val_accuracy: 0.6185\n",
      "Epoch 72/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.9481 - accuracy: 0.6570 - val_loss: 1.0449 - val_accuracy: 0.6204\n",
      "Epoch 73/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.9556 - accuracy: 0.6441 - val_loss: 1.0406 - val_accuracy: 0.6118\n",
      "Epoch 74/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.9298 - accuracy: 0.6656 - val_loss: 1.0372 - val_accuracy: 0.6213\n",
      "Epoch 75/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.9795 - accuracy: 0.6330 - val_loss: 1.0342 - val_accuracy: 0.6213\n",
      "Epoch 76/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.9426 - accuracy: 0.6573 - val_loss: 1.0315 - val_accuracy: 0.6242\n",
      "Epoch 77/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.9306 - accuracy: 0.6541 - val_loss: 1.0289 - val_accuracy: 0.6213\n",
      "Epoch 78/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.9439 - accuracy: 0.6541 - val_loss: 1.0274 - val_accuracy: 0.6213\n",
      "Epoch 79/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.9614 - accuracy: 0.6456 - val_loss: 1.0256 - val_accuracy: 0.6213\n",
      "Epoch 80/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.9350 - accuracy: 0.6597 - val_loss: 1.0142 - val_accuracy: 0.6232\n",
      "Epoch 81/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.9239 - accuracy: 0.6660 - val_loss: 1.0147 - val_accuracy: 0.6242\n",
      "Epoch 82/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.9152 - accuracy: 0.6679 - val_loss: 1.0159 - val_accuracy: 0.6232\n",
      "Epoch 83/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.9235 - accuracy: 0.6560 - val_loss: 1.0122 - val_accuracy: 0.6270\n",
      "Epoch 84/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.9350 - accuracy: 0.6570 - val_loss: 1.0174 - val_accuracy: 0.6242\n",
      "Epoch 85/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.9035 - accuracy: 0.6670 - val_loss: 0.9998 - val_accuracy: 0.6299\n",
      "Epoch 86/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.9354 - accuracy: 0.6592 - val_loss: 0.9976 - val_accuracy: 0.6289\n",
      "Epoch 87/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.8941 - accuracy: 0.6697 - val_loss: 1.0006 - val_accuracy: 0.6318\n",
      "Epoch 88/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.9237 - accuracy: 0.6538 - val_loss: 0.9948 - val_accuracy: 0.6299\n",
      "Epoch 89/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.9135 - accuracy: 0.6584 - val_loss: 0.9884 - val_accuracy: 0.6375\n",
      "Epoch 90/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.8921 - accuracy: 0.6573 - val_loss: 0.9926 - val_accuracy: 0.6308\n",
      "Epoch 91/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.9069 - accuracy: 0.6661 - val_loss: 0.9881 - val_accuracy: 0.6299\n",
      "Epoch 92/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8791 - accuracy: 0.6766 - val_loss: 0.9830 - val_accuracy: 0.6394\n",
      "Epoch 93/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8984 - accuracy: 0.6620 - val_loss: 0.9913 - val_accuracy: 0.6270\n",
      "Epoch 94/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.9084 - accuracy: 0.6640 - val_loss: 0.9963 - val_accuracy: 0.6232\n",
      "Epoch 95/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.8749 - accuracy: 0.6786 - val_loss: 0.9823 - val_accuracy: 0.6327\n",
      "Epoch 96/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.8685 - accuracy: 0.6766 - val_loss: 0.9721 - val_accuracy: 0.6375\n",
      "Epoch 97/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8892 - accuracy: 0.6647 - val_loss: 0.9734 - val_accuracy: 0.6365\n",
      "Epoch 98/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8620 - accuracy: 0.6828 - val_loss: 0.9749 - val_accuracy: 0.6394\n",
      "Epoch 99/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8822 - accuracy: 0.6775 - val_loss: 0.9706 - val_accuracy: 0.6451\n",
      "Epoch 100/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8766 - accuracy: 0.6776 - val_loss: 0.9706 - val_accuracy: 0.6422\n",
      "Epoch 101/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.8423 - accuracy: 0.6817 - val_loss: 0.9628 - val_accuracy: 0.6461\n",
      "Epoch 102/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8884 - accuracy: 0.6707 - val_loss: 0.9794 - val_accuracy: 0.6308\n",
      "Epoch 103/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8697 - accuracy: 0.6814 - val_loss: 0.9588 - val_accuracy: 0.6508\n",
      "Epoch 104/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.8516 - accuracy: 0.6818 - val_loss: 0.9614 - val_accuracy: 0.6499\n",
      "Epoch 105/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8767 - accuracy: 0.6714 - val_loss: 0.9571 - val_accuracy: 0.6527\n",
      "Epoch 106/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8716 - accuracy: 0.6806 - val_loss: 0.9511 - val_accuracy: 0.6499\n",
      "Epoch 107/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.8588 - accuracy: 0.6806 - val_loss: 0.9517 - val_accuracy: 0.6470\n",
      "Epoch 108/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8484 - accuracy: 0.6909 - val_loss: 0.9529 - val_accuracy: 0.6499\n",
      "Epoch 109/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.8548 - accuracy: 0.6729 - val_loss: 0.9506 - val_accuracy: 0.6499\n",
      "Epoch 110/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.8504 - accuracy: 0.6818 - val_loss: 0.9542 - val_accuracy: 0.6508\n",
      "Epoch 111/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8638 - accuracy: 0.6814 - val_loss: 0.9413 - val_accuracy: 0.6546\n",
      "Epoch 112/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8444 - accuracy: 0.6856 - val_loss: 0.9381 - val_accuracy: 0.6584\n",
      "Epoch 113/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8570 - accuracy: 0.6723 - val_loss: 0.9454 - val_accuracy: 0.6489\n",
      "Epoch 114/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8609 - accuracy: 0.6806 - val_loss: 0.9409 - val_accuracy: 0.6527\n",
      "Epoch 115/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8732 - accuracy: 0.6628 - val_loss: 0.9305 - val_accuracy: 0.6641\n",
      "Epoch 116/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8473 - accuracy: 0.6759 - val_loss: 0.9389 - val_accuracy: 0.6508\n",
      "Epoch 117/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8316 - accuracy: 0.6941 - val_loss: 0.9369 - val_accuracy: 0.6565\n",
      "Epoch 118/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.8382 - accuracy: 0.6920 - val_loss: 0.9257 - val_accuracy: 0.6613\n",
      "Epoch 119/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8279 - accuracy: 0.6949 - val_loss: 0.9295 - val_accuracy: 0.6584\n",
      "Epoch 120/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8534 - accuracy: 0.6823 - val_loss: 0.9311 - val_accuracy: 0.6603\n",
      "Epoch 121/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8258 - accuracy: 0.6908 - val_loss: 0.9210 - val_accuracy: 0.6613\n",
      "Epoch 122/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.8636 - accuracy: 0.6792 - val_loss: 0.9256 - val_accuracy: 0.6565\n",
      "Epoch 123/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8213 - accuracy: 0.6931 - val_loss: 0.9210 - val_accuracy: 0.6689\n",
      "Epoch 124/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8459 - accuracy: 0.6780 - val_loss: 0.9312 - val_accuracy: 0.6537\n",
      "Epoch 125/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.8194 - accuracy: 0.7016 - val_loss: 0.9255 - val_accuracy: 0.6565\n",
      "Epoch 126/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8123 - accuracy: 0.6952 - val_loss: 0.9198 - val_accuracy: 0.6708\n",
      "Epoch 127/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8210 - accuracy: 0.6977 - val_loss: 0.9225 - val_accuracy: 0.6565\n",
      "Epoch 128/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8217 - accuracy: 0.6966 - val_loss: 0.9236 - val_accuracy: 0.6651\n",
      "Epoch 129/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.8323 - accuracy: 0.6972 - val_loss: 0.9216 - val_accuracy: 0.6679\n",
      "Epoch 130/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.8012 - accuracy: 0.7013 - val_loss: 0.9023 - val_accuracy: 0.6717\n",
      "Epoch 131/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8053 - accuracy: 0.6992 - val_loss: 0.9191 - val_accuracy: 0.6622\n",
      "Epoch 132/500\n",
      "132/132 [==============================] - 2s 11ms/step - loss: 0.8135 - accuracy: 0.6894 - val_loss: 0.9173 - val_accuracy: 0.6632\n",
      "Epoch 133/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8103 - accuracy: 0.6995 - val_loss: 0.9089 - val_accuracy: 0.6651\n",
      "Epoch 134/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8051 - accuracy: 0.6991 - val_loss: 0.8957 - val_accuracy: 0.6736\n",
      "Epoch 135/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8143 - accuracy: 0.6948 - val_loss: 0.9082 - val_accuracy: 0.6708\n",
      "Epoch 136/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.8207 - accuracy: 0.6972 - val_loss: 0.9062 - val_accuracy: 0.6651\n",
      "Epoch 137/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.7941 - accuracy: 0.7062 - val_loss: 0.9005 - val_accuracy: 0.6727\n",
      "Epoch 138/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.7917 - accuracy: 0.7065 - val_loss: 0.8975 - val_accuracy: 0.6660\n",
      "Epoch 139/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.7927 - accuracy: 0.7046 - val_loss: 0.8971 - val_accuracy: 0.6689\n",
      "Epoch 140/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.7805 - accuracy: 0.7120 - val_loss: 0.8939 - val_accuracy: 0.6765\n",
      "Epoch 141/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7989 - accuracy: 0.7013 - val_loss: 0.8878 - val_accuracy: 0.6746\n",
      "Epoch 142/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8083 - accuracy: 0.7042 - val_loss: 0.8848 - val_accuracy: 0.6784\n",
      "Epoch 143/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7959 - accuracy: 0.7157 - val_loss: 0.8867 - val_accuracy: 0.6784\n",
      "Epoch 144/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.7749 - accuracy: 0.7124 - val_loss: 0.8837 - val_accuracy: 0.6717\n",
      "Epoch 145/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7804 - accuracy: 0.7148 - val_loss: 0.8830 - val_accuracy: 0.6755\n",
      "Epoch 146/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7721 - accuracy: 0.7127 - val_loss: 0.8862 - val_accuracy: 0.6708\n",
      "Epoch 147/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7769 - accuracy: 0.7144 - val_loss: 0.8776 - val_accuracy: 0.6860\n",
      "Epoch 148/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.8093 - accuracy: 0.7058 - val_loss: 0.8803 - val_accuracy: 0.6698\n",
      "Epoch 149/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8015 - accuracy: 0.7073 - val_loss: 0.8780 - val_accuracy: 0.6784\n",
      "Epoch 150/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7620 - accuracy: 0.7152 - val_loss: 0.8819 - val_accuracy: 0.6794\n",
      "Epoch 151/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7707 - accuracy: 0.7168 - val_loss: 0.8891 - val_accuracy: 0.6746\n",
      "Epoch 152/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7700 - accuracy: 0.7103 - val_loss: 0.8774 - val_accuracy: 0.6746\n",
      "Epoch 153/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7854 - accuracy: 0.7105 - val_loss: 0.8750 - val_accuracy: 0.6717\n",
      "Epoch 154/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7941 - accuracy: 0.7130 - val_loss: 0.8649 - val_accuracy: 0.6860\n",
      "Epoch 155/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7849 - accuracy: 0.7060 - val_loss: 0.8745 - val_accuracy: 0.6775\n",
      "Epoch 156/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7860 - accuracy: 0.7089 - val_loss: 0.8657 - val_accuracy: 0.6841\n",
      "Epoch 157/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7710 - accuracy: 0.7157 - val_loss: 0.8627 - val_accuracy: 0.6822\n",
      "Epoch 158/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7903 - accuracy: 0.7043 - val_loss: 0.8617 - val_accuracy: 0.6784\n",
      "Epoch 159/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7852 - accuracy: 0.7085 - val_loss: 0.8665 - val_accuracy: 0.6736\n",
      "Epoch 160/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.8087 - accuracy: 0.6937 - val_loss: 0.8632 - val_accuracy: 0.6851\n",
      "Epoch 161/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7812 - accuracy: 0.7114 - val_loss: 0.8593 - val_accuracy: 0.6898\n",
      "Epoch 162/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.7788 - accuracy: 0.7251 - val_loss: 0.8510 - val_accuracy: 0.6917\n",
      "Epoch 163/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.7539 - accuracy: 0.7316 - val_loss: 0.8511 - val_accuracy: 0.6870\n",
      "Epoch 164/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7716 - accuracy: 0.7154 - val_loss: 0.8554 - val_accuracy: 0.6851\n",
      "Epoch 165/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7722 - accuracy: 0.7129 - val_loss: 0.8575 - val_accuracy: 0.6917\n",
      "Epoch 166/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7754 - accuracy: 0.7157 - val_loss: 0.8480 - val_accuracy: 0.6927\n",
      "Epoch 167/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7868 - accuracy: 0.7068 - val_loss: 0.8456 - val_accuracy: 0.6927\n",
      "Epoch 168/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.7465 - accuracy: 0.7258 - val_loss: 0.8502 - val_accuracy: 0.6908\n",
      "Epoch 169/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7489 - accuracy: 0.7287 - val_loss: 0.8551 - val_accuracy: 0.6879\n",
      "Epoch 170/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7549 - accuracy: 0.7204 - val_loss: 0.8453 - val_accuracy: 0.6851\n",
      "Epoch 171/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7595 - accuracy: 0.7222 - val_loss: 0.8411 - val_accuracy: 0.6917\n",
      "Epoch 172/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7415 - accuracy: 0.7303 - val_loss: 0.8569 - val_accuracy: 0.6832\n",
      "Epoch 173/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7468 - accuracy: 0.7303 - val_loss: 0.8486 - val_accuracy: 0.6832\n",
      "Epoch 174/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7280 - accuracy: 0.7316 - val_loss: 0.8448 - val_accuracy: 0.6794\n",
      "Epoch 175/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.7413 - accuracy: 0.7238 - val_loss: 0.8419 - val_accuracy: 0.6917\n",
      "Epoch 176/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.7472 - accuracy: 0.7229 - val_loss: 0.8398 - val_accuracy: 0.6936\n",
      "Epoch 177/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7490 - accuracy: 0.7225 - val_loss: 0.8401 - val_accuracy: 0.6870\n",
      "Epoch 178/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7595 - accuracy: 0.7209 - val_loss: 0.8403 - val_accuracy: 0.6870\n",
      "Epoch 179/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7478 - accuracy: 0.7222 - val_loss: 0.8407 - val_accuracy: 0.6927\n",
      "Epoch 180/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7206 - accuracy: 0.7387 - val_loss: 0.8327 - val_accuracy: 0.6993\n",
      "Epoch 181/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.7376 - accuracy: 0.7286 - val_loss: 0.8320 - val_accuracy: 0.6927\n",
      "Epoch 182/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7469 - accuracy: 0.7239 - val_loss: 0.8337 - val_accuracy: 0.6974\n",
      "Epoch 183/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7430 - accuracy: 0.7184 - val_loss: 0.8315 - val_accuracy: 0.6879\n",
      "Epoch 184/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.7445 - accuracy: 0.7315 - val_loss: 0.8227 - val_accuracy: 0.7003\n",
      "Epoch 185/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7197 - accuracy: 0.7302 - val_loss: 0.8320 - val_accuracy: 0.6974\n",
      "Epoch 186/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7086 - accuracy: 0.7350 - val_loss: 0.8257 - val_accuracy: 0.6927\n",
      "Epoch 187/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7490 - accuracy: 0.7238 - val_loss: 0.8437 - val_accuracy: 0.6927\n",
      "Epoch 188/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7483 - accuracy: 0.7284 - val_loss: 0.8279 - val_accuracy: 0.6908\n",
      "Epoch 189/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7175 - accuracy: 0.7310 - val_loss: 0.8222 - val_accuracy: 0.6927\n",
      "Epoch 190/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7243 - accuracy: 0.7269 - val_loss: 0.8174 - val_accuracy: 0.7003\n",
      "Epoch 191/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7538 - accuracy: 0.7272 - val_loss: 0.8214 - val_accuracy: 0.6984\n",
      "Epoch 192/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7285 - accuracy: 0.7408 - val_loss: 0.8285 - val_accuracy: 0.6936\n",
      "Epoch 193/500\n",
      "132/132 [==============================] - 1s 9ms/step - loss: 0.7228 - accuracy: 0.7377 - val_loss: 0.8210 - val_accuracy: 0.6993\n",
      "Epoch 194/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7246 - accuracy: 0.7373 - val_loss: 0.8141 - val_accuracy: 0.7012\n",
      "Epoch 195/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7184 - accuracy: 0.7331 - val_loss: 0.8246 - val_accuracy: 0.6851\n",
      "Epoch 196/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7215 - accuracy: 0.7313 - val_loss: 0.8106 - val_accuracy: 0.7041\n",
      "Epoch 197/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7138 - accuracy: 0.7372 - val_loss: 0.8170 - val_accuracy: 0.7003\n",
      "Epoch 198/500\n",
      "132/132 [==============================] - 2s 11ms/step - loss: 0.7261 - accuracy: 0.7285 - val_loss: 0.8148 - val_accuracy: 0.6917\n",
      "Epoch 199/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.7338 - accuracy: 0.7246 - val_loss: 0.8141 - val_accuracy: 0.7012\n",
      "Epoch 200/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7350 - accuracy: 0.7240 - val_loss: 0.8161 - val_accuracy: 0.6917\n",
      "Epoch 201/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7019 - accuracy: 0.7439 - val_loss: 0.8197 - val_accuracy: 0.6936\n",
      "Epoch 202/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7045 - accuracy: 0.7359 - val_loss: 0.8098 - val_accuracy: 0.6965\n",
      "Epoch 203/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7050 - accuracy: 0.7451 - val_loss: 0.8091 - val_accuracy: 0.6955\n",
      "Epoch 204/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7165 - accuracy: 0.7312 - val_loss: 0.8008 - val_accuracy: 0.7193\n",
      "Epoch 205/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7160 - accuracy: 0.7358 - val_loss: 0.8046 - val_accuracy: 0.7088\n",
      "Epoch 206/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.7233 - accuracy: 0.7451 - val_loss: 0.8108 - val_accuracy: 0.6927\n",
      "Epoch 207/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6923 - accuracy: 0.7413 - val_loss: 0.8003 - val_accuracy: 0.7165\n",
      "Epoch 208/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7178 - accuracy: 0.7440 - val_loss: 0.7992 - val_accuracy: 0.7184\n",
      "Epoch 209/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6817 - accuracy: 0.7519 - val_loss: 0.8023 - val_accuracy: 0.7108\n",
      "Epoch 210/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7194 - accuracy: 0.7378 - val_loss: 0.8114 - val_accuracy: 0.6936\n",
      "Epoch 211/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7027 - accuracy: 0.7450 - val_loss: 0.7942 - val_accuracy: 0.7117\n",
      "Epoch 212/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7235 - accuracy: 0.7313 - val_loss: 0.7946 - val_accuracy: 0.7050\n",
      "Epoch 213/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7207 - accuracy: 0.7374 - val_loss: 0.8048 - val_accuracy: 0.7050\n",
      "Epoch 214/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.6946 - accuracy: 0.7543 - val_loss: 0.7945 - val_accuracy: 0.7136\n",
      "Epoch 215/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.7128 - accuracy: 0.7384 - val_loss: 0.7906 - val_accuracy: 0.7117\n",
      "Epoch 216/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6826 - accuracy: 0.7470 - val_loss: 0.8056 - val_accuracy: 0.7003\n",
      "Epoch 217/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6909 - accuracy: 0.7468 - val_loss: 0.7888 - val_accuracy: 0.7212\n",
      "Epoch 218/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6733 - accuracy: 0.7564 - val_loss: 0.7949 - val_accuracy: 0.7098\n",
      "Epoch 219/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6715 - accuracy: 0.7556 - val_loss: 0.7898 - val_accuracy: 0.7146\n",
      "Epoch 220/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7089 - accuracy: 0.7325 - val_loss: 0.7854 - val_accuracy: 0.7250\n",
      "Epoch 221/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6806 - accuracy: 0.7545 - val_loss: 0.7848 - val_accuracy: 0.7155\n",
      "Epoch 222/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7067 - accuracy: 0.7379 - val_loss: 0.7872 - val_accuracy: 0.7127\n",
      "Epoch 223/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6756 - accuracy: 0.7511 - val_loss: 0.7897 - val_accuracy: 0.7165\n",
      "Epoch 224/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6955 - accuracy: 0.7455 - val_loss: 0.7833 - val_accuracy: 0.7136\n",
      "Epoch 225/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7031 - accuracy: 0.7400 - val_loss: 0.7936 - val_accuracy: 0.7146\n",
      "Epoch 226/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6893 - accuracy: 0.7443 - val_loss: 0.7829 - val_accuracy: 0.7165\n",
      "Epoch 227/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6819 - accuracy: 0.7523 - val_loss: 0.7814 - val_accuracy: 0.7212\n",
      "Epoch 228/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6992 - accuracy: 0.7429 - val_loss: 0.7748 - val_accuracy: 0.7241\n",
      "Epoch 229/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6607 - accuracy: 0.7552 - val_loss: 0.7759 - val_accuracy: 0.7260\n",
      "Epoch 230/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6831 - accuracy: 0.7465 - val_loss: 0.7839 - val_accuracy: 0.7108\n",
      "Epoch 231/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6978 - accuracy: 0.7481 - val_loss: 0.7721 - val_accuracy: 0.7279\n",
      "Epoch 232/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6744 - accuracy: 0.7561 - val_loss: 0.7902 - val_accuracy: 0.7079\n",
      "Epoch 233/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6603 - accuracy: 0.7593 - val_loss: 0.7709 - val_accuracy: 0.7260\n",
      "Epoch 234/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6608 - accuracy: 0.7560 - val_loss: 0.7670 - val_accuracy: 0.7326\n",
      "Epoch 235/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6597 - accuracy: 0.7591 - val_loss: 0.7825 - val_accuracy: 0.7174\n",
      "Epoch 236/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6950 - accuracy: 0.7421 - val_loss: 0.7722 - val_accuracy: 0.7174\n",
      "Epoch 237/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6698 - accuracy: 0.7611 - val_loss: 0.7772 - val_accuracy: 0.7212\n",
      "Epoch 238/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6742 - accuracy: 0.7470 - val_loss: 0.7700 - val_accuracy: 0.7193\n",
      "Epoch 239/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6641 - accuracy: 0.7504 - val_loss: 0.7721 - val_accuracy: 0.7108\n",
      "Epoch 240/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6758 - accuracy: 0.7555 - val_loss: 0.7698 - val_accuracy: 0.7241\n",
      "Epoch 241/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6850 - accuracy: 0.7503 - val_loss: 0.7622 - val_accuracy: 0.7250\n",
      "Epoch 242/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.7068 - accuracy: 0.7440 - val_loss: 0.7614 - val_accuracy: 0.7260\n",
      "Epoch 243/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6745 - accuracy: 0.7534 - val_loss: 0.7670 - val_accuracy: 0.7231\n",
      "Epoch 244/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6796 - accuracy: 0.7483 - val_loss: 0.7665 - val_accuracy: 0.7241\n",
      "Epoch 245/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6815 - accuracy: 0.7470 - val_loss: 0.7787 - val_accuracy: 0.7098\n",
      "Epoch 246/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6927 - accuracy: 0.7430 - val_loss: 0.7651 - val_accuracy: 0.7279\n",
      "Epoch 247/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6708 - accuracy: 0.7491 - val_loss: 0.7532 - val_accuracy: 0.7288\n",
      "Epoch 248/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6397 - accuracy: 0.7621 - val_loss: 0.7551 - val_accuracy: 0.7279\n",
      "Epoch 249/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6576 - accuracy: 0.7585 - val_loss: 0.7586 - val_accuracy: 0.7279\n",
      "Epoch 250/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6753 - accuracy: 0.7501 - val_loss: 0.7765 - val_accuracy: 0.7136\n",
      "Epoch 251/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6895 - accuracy: 0.7494 - val_loss: 0.7678 - val_accuracy: 0.7165\n",
      "Epoch 252/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6771 - accuracy: 0.7505 - val_loss: 0.7534 - val_accuracy: 0.7250\n",
      "Epoch 253/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6497 - accuracy: 0.7708 - val_loss: 0.7585 - val_accuracy: 0.7326\n",
      "Epoch 254/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6376 - accuracy: 0.7690 - val_loss: 0.7572 - val_accuracy: 0.7146\n",
      "Epoch 255/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6602 - accuracy: 0.7519 - val_loss: 0.7530 - val_accuracy: 0.7260\n",
      "Epoch 256/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6326 - accuracy: 0.7694 - val_loss: 0.7561 - val_accuracy: 0.7193\n",
      "Epoch 257/500\n",
      "132/132 [==============================] - 2s 11ms/step - loss: 0.6485 - accuracy: 0.7550 - val_loss: 0.7481 - val_accuracy: 0.7317\n",
      "Epoch 258/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6322 - accuracy: 0.7652 - val_loss: 0.7540 - val_accuracy: 0.7250\n",
      "Epoch 259/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6588 - accuracy: 0.7539 - val_loss: 0.7591 - val_accuracy: 0.7250\n",
      "Epoch 260/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6393 - accuracy: 0.7661 - val_loss: 0.7671 - val_accuracy: 0.7127\n",
      "Epoch 261/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6467 - accuracy: 0.7617 - val_loss: 0.7477 - val_accuracy: 0.7269\n",
      "Epoch 262/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6493 - accuracy: 0.7613 - val_loss: 0.7526 - val_accuracy: 0.7298\n",
      "Epoch 263/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6198 - accuracy: 0.7724 - val_loss: 0.7608 - val_accuracy: 0.7165\n",
      "Epoch 264/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.6418 - accuracy: 0.7592 - val_loss: 0.7502 - val_accuracy: 0.7269\n",
      "Epoch 265/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6638 - accuracy: 0.7532 - val_loss: 0.7603 - val_accuracy: 0.7155\n",
      "Epoch 266/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6356 - accuracy: 0.7701 - val_loss: 0.7405 - val_accuracy: 0.7355\n",
      "Epoch 267/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6459 - accuracy: 0.7593 - val_loss: 0.7390 - val_accuracy: 0.7345\n",
      "Epoch 268/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6620 - accuracy: 0.7661 - val_loss: 0.7481 - val_accuracy: 0.7279\n",
      "Epoch 269/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6423 - accuracy: 0.7639 - val_loss: 0.7451 - val_accuracy: 0.7298\n",
      "Epoch 270/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6457 - accuracy: 0.7613 - val_loss: 0.7556 - val_accuracy: 0.7212\n",
      "Epoch 271/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6299 - accuracy: 0.7688 - val_loss: 0.7415 - val_accuracy: 0.7326\n",
      "Epoch 272/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6492 - accuracy: 0.7605 - val_loss: 0.7429 - val_accuracy: 0.7336\n",
      "Epoch 273/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6327 - accuracy: 0.7720 - val_loss: 0.7362 - val_accuracy: 0.7288\n",
      "Epoch 274/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6481 - accuracy: 0.7572 - val_loss: 0.7360 - val_accuracy: 0.7260\n",
      "Epoch 275/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6467 - accuracy: 0.7626 - val_loss: 0.7406 - val_accuracy: 0.7288\n",
      "Epoch 276/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6079 - accuracy: 0.7748 - val_loss: 0.7394 - val_accuracy: 0.7279\n",
      "Epoch 277/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6218 - accuracy: 0.7720 - val_loss: 0.7408 - val_accuracy: 0.7307\n",
      "Epoch 278/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6222 - accuracy: 0.7647 - val_loss: 0.7345 - val_accuracy: 0.7317\n",
      "Epoch 279/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6457 - accuracy: 0.7552 - val_loss: 0.7406 - val_accuracy: 0.7383\n",
      "Epoch 280/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6341 - accuracy: 0.7670 - val_loss: 0.7378 - val_accuracy: 0.7269\n",
      "Epoch 281/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6319 - accuracy: 0.7760 - val_loss: 0.7507 - val_accuracy: 0.7184\n",
      "Epoch 282/500\n",
      "132/132 [==============================] - 2s 13ms/step - loss: 0.6467 - accuracy: 0.7623 - val_loss: 0.7388 - val_accuracy: 0.7326\n",
      "Epoch 283/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6296 - accuracy: 0.7662 - val_loss: 0.7348 - val_accuracy: 0.7307\n",
      "Epoch 284/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6339 - accuracy: 0.7638 - val_loss: 0.7342 - val_accuracy: 0.7288\n",
      "Epoch 285/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6262 - accuracy: 0.7644 - val_loss: 0.7513 - val_accuracy: 0.7279\n",
      "Epoch 286/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6386 - accuracy: 0.7560 - val_loss: 0.7286 - val_accuracy: 0.7383\n",
      "Epoch 287/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6336 - accuracy: 0.7633 - val_loss: 0.7499 - val_accuracy: 0.7184\n",
      "Epoch 288/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6271 - accuracy: 0.7697 - val_loss: 0.7261 - val_accuracy: 0.7441\n",
      "Epoch 289/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6367 - accuracy: 0.7622 - val_loss: 0.7395 - val_accuracy: 0.7269\n",
      "Epoch 290/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6397 - accuracy: 0.7654 - val_loss: 0.7391 - val_accuracy: 0.7288\n",
      "Epoch 291/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6267 - accuracy: 0.7734 - val_loss: 0.7347 - val_accuracy: 0.7231\n",
      "Epoch 292/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6352 - accuracy: 0.7716 - val_loss: 0.7389 - val_accuracy: 0.7279\n",
      "Epoch 293/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6062 - accuracy: 0.7693 - val_loss: 0.7275 - val_accuracy: 0.7326\n",
      "Epoch 294/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6009 - accuracy: 0.7816 - val_loss: 0.7184 - val_accuracy: 0.7402\n",
      "Epoch 295/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6104 - accuracy: 0.7764 - val_loss: 0.7353 - val_accuracy: 0.7317\n",
      "Epoch 296/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6178 - accuracy: 0.7740 - val_loss: 0.7244 - val_accuracy: 0.7374\n",
      "Epoch 297/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6049 - accuracy: 0.7741 - val_loss: 0.7246 - val_accuracy: 0.7326\n",
      "Epoch 298/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6143 - accuracy: 0.7791 - val_loss: 0.7215 - val_accuracy: 0.7402\n",
      "Epoch 299/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5920 - accuracy: 0.7803 - val_loss: 0.7220 - val_accuracy: 0.7383\n",
      "Epoch 300/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6128 - accuracy: 0.7664 - val_loss: 0.7227 - val_accuracy: 0.7383\n",
      "Epoch 301/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6085 - accuracy: 0.7785 - val_loss: 0.7136 - val_accuracy: 0.7422\n",
      "Epoch 302/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5963 - accuracy: 0.7783 - val_loss: 0.7308 - val_accuracy: 0.7269\n",
      "Epoch 303/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6041 - accuracy: 0.7807 - val_loss: 0.7172 - val_accuracy: 0.7402\n",
      "Epoch 304/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6154 - accuracy: 0.7702 - val_loss: 0.7270 - val_accuracy: 0.7326\n",
      "Epoch 305/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6026 - accuracy: 0.7712 - val_loss: 0.7113 - val_accuracy: 0.7488\n",
      "Epoch 306/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6157 - accuracy: 0.7745 - val_loss: 0.7143 - val_accuracy: 0.7374\n",
      "Epoch 307/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6571 - accuracy: 0.7503 - val_loss: 0.7201 - val_accuracy: 0.7441\n",
      "Epoch 308/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5970 - accuracy: 0.7807 - val_loss: 0.7202 - val_accuracy: 0.7374\n",
      "Epoch 309/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6132 - accuracy: 0.7766 - val_loss: 0.7179 - val_accuracy: 0.7488\n",
      "Epoch 310/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6011 - accuracy: 0.7744 - val_loss: 0.7151 - val_accuracy: 0.7345\n",
      "Epoch 311/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5817 - accuracy: 0.7837 - val_loss: 0.7142 - val_accuracy: 0.7460\n",
      "Epoch 312/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6107 - accuracy: 0.7834 - val_loss: 0.7082 - val_accuracy: 0.7412\n",
      "Epoch 313/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5963 - accuracy: 0.7771 - val_loss: 0.7211 - val_accuracy: 0.7326\n",
      "Epoch 314/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6052 - accuracy: 0.7678 - val_loss: 0.7082 - val_accuracy: 0.7431\n",
      "Epoch 315/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5907 - accuracy: 0.7897 - val_loss: 0.7135 - val_accuracy: 0.7441\n",
      "Epoch 316/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5986 - accuracy: 0.7756 - val_loss: 0.7118 - val_accuracy: 0.7450\n",
      "Epoch 317/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6036 - accuracy: 0.7781 - val_loss: 0.7167 - val_accuracy: 0.7412\n",
      "Epoch 318/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6096 - accuracy: 0.7697 - val_loss: 0.7167 - val_accuracy: 0.7364\n",
      "Epoch 319/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6054 - accuracy: 0.7694 - val_loss: 0.7105 - val_accuracy: 0.7402\n",
      "Epoch 320/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6001 - accuracy: 0.7748 - val_loss: 0.7100 - val_accuracy: 0.7441\n",
      "Epoch 321/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5899 - accuracy: 0.7815 - val_loss: 0.7111 - val_accuracy: 0.7441\n",
      "Epoch 322/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5905 - accuracy: 0.7847 - val_loss: 0.7051 - val_accuracy: 0.7526\n",
      "Epoch 323/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6055 - accuracy: 0.7733 - val_loss: 0.7097 - val_accuracy: 0.7441\n",
      "Epoch 324/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5871 - accuracy: 0.7864 - val_loss: 0.7069 - val_accuracy: 0.7393\n",
      "Epoch 325/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6034 - accuracy: 0.7771 - val_loss: 0.7002 - val_accuracy: 0.7498\n",
      "Epoch 326/500\n",
      "132/132 [==============================] - 2s 11ms/step - loss: 0.6052 - accuracy: 0.7744 - val_loss: 0.7101 - val_accuracy: 0.7298\n",
      "Epoch 327/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5940 - accuracy: 0.7720 - val_loss: 0.7060 - val_accuracy: 0.7450\n",
      "Epoch 328/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.5524 - accuracy: 0.7979 - val_loss: 0.7057 - val_accuracy: 0.7393\n",
      "Epoch 329/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.6086 - accuracy: 0.7676 - val_loss: 0.7073 - val_accuracy: 0.7345\n",
      "Epoch 330/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5999 - accuracy: 0.7682 - val_loss: 0.7069 - val_accuracy: 0.7402\n",
      "Epoch 331/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5938 - accuracy: 0.7813 - val_loss: 0.7066 - val_accuracy: 0.7422\n",
      "Epoch 332/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.6072 - accuracy: 0.7823 - val_loss: 0.7052 - val_accuracy: 0.7412\n",
      "Epoch 333/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.5837 - accuracy: 0.7861 - val_loss: 0.7049 - val_accuracy: 0.7422\n",
      "Epoch 334/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5813 - accuracy: 0.7812 - val_loss: 0.7013 - val_accuracy: 0.7393\n",
      "Epoch 335/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5869 - accuracy: 0.7855 - val_loss: 0.7074 - val_accuracy: 0.7431\n",
      "Epoch 336/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5937 - accuracy: 0.7893 - val_loss: 0.6964 - val_accuracy: 0.7488\n",
      "Epoch 337/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.5921 - accuracy: 0.7797 - val_loss: 0.7108 - val_accuracy: 0.7383\n",
      "Epoch 338/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5828 - accuracy: 0.7889 - val_loss: 0.7096 - val_accuracy: 0.7460\n",
      "Epoch 339/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5966 - accuracy: 0.7824 - val_loss: 0.7088 - val_accuracy: 0.7412\n",
      "Epoch 340/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5750 - accuracy: 0.7907 - val_loss: 0.6946 - val_accuracy: 0.7460\n",
      "Epoch 341/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.5698 - accuracy: 0.7856 - val_loss: 0.6869 - val_accuracy: 0.7536\n",
      "Epoch 342/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.6000 - accuracy: 0.7759 - val_loss: 0.7048 - val_accuracy: 0.7441\n",
      "Epoch 343/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5659 - accuracy: 0.7896 - val_loss: 0.6954 - val_accuracy: 0.7488\n",
      "Epoch 344/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5749 - accuracy: 0.7861 - val_loss: 0.7154 - val_accuracy: 0.7298\n",
      "Epoch 345/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.5911 - accuracy: 0.7812 - val_loss: 0.6988 - val_accuracy: 0.7402\n",
      "Epoch 346/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5628 - accuracy: 0.7963 - val_loss: 0.7075 - val_accuracy: 0.7422\n",
      "Epoch 347/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5825 - accuracy: 0.7841 - val_loss: 0.7108 - val_accuracy: 0.7374\n",
      "Epoch 348/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5667 - accuracy: 0.7885 - val_loss: 0.7068 - val_accuracy: 0.7336\n",
      "Epoch 349/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.5755 - accuracy: 0.7888 - val_loss: 0.6971 - val_accuracy: 0.7441\n",
      "Epoch 350/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5815 - accuracy: 0.7884 - val_loss: 0.7010 - val_accuracy: 0.7383\n",
      "Epoch 351/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5908 - accuracy: 0.7796 - val_loss: 0.6910 - val_accuracy: 0.7450\n",
      "Epoch 352/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5773 - accuracy: 0.7893 - val_loss: 0.6973 - val_accuracy: 0.7460\n",
      "Epoch 353/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.5712 - accuracy: 0.7922 - val_loss: 0.7026 - val_accuracy: 0.7526\n",
      "Epoch 354/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.5442 - accuracy: 0.7923 - val_loss: 0.6884 - val_accuracy: 0.7507\n",
      "Epoch 355/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5762 - accuracy: 0.7827 - val_loss: 0.6926 - val_accuracy: 0.7450\n",
      "Epoch 356/500\n",
      "132/132 [==============================] - 2s 11ms/step - loss: 0.5701 - accuracy: 0.7893 - val_loss: 0.6860 - val_accuracy: 0.7469\n",
      "Epoch 357/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5748 - accuracy: 0.7848 - val_loss: 0.6871 - val_accuracy: 0.7507\n",
      "Epoch 358/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5986 - accuracy: 0.7844 - val_loss: 0.7050 - val_accuracy: 0.7441\n",
      "Epoch 359/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5802 - accuracy: 0.7817 - val_loss: 0.6988 - val_accuracy: 0.7469\n",
      "Epoch 360/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5533 - accuracy: 0.7999 - val_loss: 0.6894 - val_accuracy: 0.7564\n",
      "Epoch 361/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5723 - accuracy: 0.7838 - val_loss: 0.6898 - val_accuracy: 0.7441\n",
      "Epoch 362/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5765 - accuracy: 0.7817 - val_loss: 0.6848 - val_accuracy: 0.7536\n",
      "Epoch 363/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5669 - accuracy: 0.7932 - val_loss: 0.6862 - val_accuracy: 0.7574\n",
      "Epoch 364/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5291 - accuracy: 0.8036 - val_loss: 0.6890 - val_accuracy: 0.7488\n",
      "Epoch 365/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5603 - accuracy: 0.7890 - val_loss: 0.6862 - val_accuracy: 0.7488\n",
      "Epoch 366/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5554 - accuracy: 0.7875 - val_loss: 0.6841 - val_accuracy: 0.7498\n",
      "Epoch 367/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5532 - accuracy: 0.7944 - val_loss: 0.6926 - val_accuracy: 0.7498\n",
      "Epoch 368/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.5410 - accuracy: 0.8002 - val_loss: 0.6943 - val_accuracy: 0.7450\n",
      "Epoch 369/500\n",
      "132/132 [==============================] - 2s 11ms/step - loss: 0.5482 - accuracy: 0.7983 - val_loss: 0.6915 - val_accuracy: 0.7536\n",
      "Epoch 370/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5711 - accuracy: 0.7883 - val_loss: 0.6948 - val_accuracy: 0.7431\n",
      "Epoch 371/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5741 - accuracy: 0.7805 - val_loss: 0.6964 - val_accuracy: 0.7469\n",
      "Epoch 372/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5654 - accuracy: 0.7900 - val_loss: 0.6838 - val_accuracy: 0.7564\n",
      "Epoch 373/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5615 - accuracy: 0.7910 - val_loss: 0.6989 - val_accuracy: 0.7536\n",
      "Epoch 374/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5721 - accuracy: 0.7893 - val_loss: 0.6871 - val_accuracy: 0.7507\n",
      "Epoch 375/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5863 - accuracy: 0.7785 - val_loss: 0.6904 - val_accuracy: 0.7460\n",
      "Epoch 376/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5638 - accuracy: 0.7927 - val_loss: 0.6908 - val_accuracy: 0.7469\n",
      "Epoch 377/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5560 - accuracy: 0.7959 - val_loss: 0.6792 - val_accuracy: 0.7536\n",
      "Epoch 378/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5762 - accuracy: 0.7912 - val_loss: 0.6964 - val_accuracy: 0.7374\n",
      "Epoch 379/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5388 - accuracy: 0.7979 - val_loss: 0.6857 - val_accuracy: 0.7479\n",
      "Epoch 380/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5958 - accuracy: 0.7704 - val_loss: 0.6908 - val_accuracy: 0.7583\n",
      "Epoch 381/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.5373 - accuracy: 0.7966 - val_loss: 0.6864 - val_accuracy: 0.7488\n",
      "Epoch 382/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5431 - accuracy: 0.7992 - val_loss: 0.6863 - val_accuracy: 0.7507\n",
      "Epoch 383/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.5445 - accuracy: 0.7922 - val_loss: 0.6883 - val_accuracy: 0.7488\n",
      "Epoch 384/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5530 - accuracy: 0.7904 - val_loss: 0.6815 - val_accuracy: 0.7441\n",
      "Epoch 385/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5267 - accuracy: 0.7995 - val_loss: 0.6724 - val_accuracy: 0.7574\n",
      "Epoch 386/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.5533 - accuracy: 0.8047 - val_loss: 0.6816 - val_accuracy: 0.7574\n",
      "Epoch 387/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5503 - accuracy: 0.8031 - val_loss: 0.6819 - val_accuracy: 0.7517\n",
      "Epoch 388/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5582 - accuracy: 0.7870 - val_loss: 0.6831 - val_accuracy: 0.7498\n",
      "Epoch 389/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5310 - accuracy: 0.8002 - val_loss: 0.6751 - val_accuracy: 0.7574\n",
      "Epoch 390/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5441 - accuracy: 0.7934 - val_loss: 0.6805 - val_accuracy: 0.7536\n",
      "Epoch 391/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5494 - accuracy: 0.7948 - val_loss: 0.6746 - val_accuracy: 0.7507\n",
      "Epoch 392/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5392 - accuracy: 0.7962 - val_loss: 0.6841 - val_accuracy: 0.7536\n",
      "Epoch 393/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5216 - accuracy: 0.7997 - val_loss: 0.6734 - val_accuracy: 0.7583\n",
      "Epoch 394/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.5626 - accuracy: 0.7864 - val_loss: 0.6714 - val_accuracy: 0.7564\n",
      "Epoch 395/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.5385 - accuracy: 0.7984 - val_loss: 0.6794 - val_accuracy: 0.7479\n",
      "Epoch 396/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5368 - accuracy: 0.7941 - val_loss: 0.6704 - val_accuracy: 0.7564\n",
      "Epoch 397/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5453 - accuracy: 0.7974 - val_loss: 0.6797 - val_accuracy: 0.7479\n",
      "Epoch 398/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5302 - accuracy: 0.8011 - val_loss: 0.6685 - val_accuracy: 0.7659\n",
      "Epoch 399/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.5368 - accuracy: 0.7903 - val_loss: 0.6805 - val_accuracy: 0.7659\n",
      "Epoch 400/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5199 - accuracy: 0.8067 - val_loss: 0.6890 - val_accuracy: 0.7517\n",
      "Epoch 401/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5401 - accuracy: 0.7968 - val_loss: 0.6729 - val_accuracy: 0.7526\n",
      "Epoch 402/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5446 - accuracy: 0.7921 - val_loss: 0.6746 - val_accuracy: 0.7507\n",
      "Epoch 403/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5187 - accuracy: 0.8052 - val_loss: 0.6810 - val_accuracy: 0.7536\n",
      "Epoch 404/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5641 - accuracy: 0.7909 - val_loss: 0.6803 - val_accuracy: 0.7498\n",
      "Epoch 405/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5284 - accuracy: 0.8102 - val_loss: 0.6781 - val_accuracy: 0.7574\n",
      "Epoch 406/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5174 - accuracy: 0.8092 - val_loss: 0.6748 - val_accuracy: 0.7536\n",
      "Epoch 407/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5578 - accuracy: 0.7921 - val_loss: 0.6829 - val_accuracy: 0.7498\n",
      "Epoch 408/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5062 - accuracy: 0.8166 - val_loss: 0.6734 - val_accuracy: 0.7469\n",
      "Epoch 409/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5472 - accuracy: 0.8047 - val_loss: 0.6736 - val_accuracy: 0.7564\n",
      "Epoch 410/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.5027 - accuracy: 0.8144 - val_loss: 0.6692 - val_accuracy: 0.7583\n",
      "Epoch 411/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5308 - accuracy: 0.8018 - val_loss: 0.6695 - val_accuracy: 0.7488\n",
      "Epoch 412/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5427 - accuracy: 0.7941 - val_loss: 0.6663 - val_accuracy: 0.7612\n",
      "Epoch 413/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5251 - accuracy: 0.8042 - val_loss: 0.6780 - val_accuracy: 0.7574\n",
      "Epoch 414/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.5459 - accuracy: 0.7988 - val_loss: 0.6748 - val_accuracy: 0.7564\n",
      "Epoch 415/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5202 - accuracy: 0.8058 - val_loss: 0.6747 - val_accuracy: 0.7555\n",
      "Epoch 416/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5556 - accuracy: 0.7978 - val_loss: 0.6797 - val_accuracy: 0.7517\n",
      "Epoch 417/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5302 - accuracy: 0.8011 - val_loss: 0.6836 - val_accuracy: 0.7555\n",
      "Epoch 418/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5383 - accuracy: 0.7964 - val_loss: 0.6819 - val_accuracy: 0.7526\n",
      "Epoch 419/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5319 - accuracy: 0.8001 - val_loss: 0.6656 - val_accuracy: 0.7621\n",
      "Epoch 420/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5318 - accuracy: 0.7983 - val_loss: 0.6700 - val_accuracy: 0.7574\n",
      "Epoch 421/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5354 - accuracy: 0.8042 - val_loss: 0.6616 - val_accuracy: 0.7536\n",
      "Epoch 422/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.5372 - accuracy: 0.7981 - val_loss: 0.6774 - val_accuracy: 0.7450\n",
      "Epoch 423/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5039 - accuracy: 0.8145 - val_loss: 0.6736 - val_accuracy: 0.7602\n",
      "Epoch 424/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5215 - accuracy: 0.8080 - val_loss: 0.6724 - val_accuracy: 0.7555\n",
      "Epoch 425/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5137 - accuracy: 0.8111 - val_loss: 0.6675 - val_accuracy: 0.7602\n",
      "Epoch 426/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.5360 - accuracy: 0.8073 - val_loss: 0.6636 - val_accuracy: 0.7640\n",
      "Epoch 427/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5218 - accuracy: 0.8054 - val_loss: 0.6731 - val_accuracy: 0.7498\n",
      "Epoch 428/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5142 - accuracy: 0.8140 - val_loss: 0.6747 - val_accuracy: 0.7593\n",
      "Epoch 429/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5120 - accuracy: 0.8143 - val_loss: 0.6597 - val_accuracy: 0.7640\n",
      "Epoch 430/500\n",
      "132/132 [==============================] - 2s 11ms/step - loss: 0.5167 - accuracy: 0.8087 - val_loss: 0.6710 - val_accuracy: 0.7631\n",
      "Epoch 431/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5006 - accuracy: 0.8138 - val_loss: 0.6590 - val_accuracy: 0.7678\n",
      "Epoch 432/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.5161 - accuracy: 0.8066 - val_loss: 0.6794 - val_accuracy: 0.7536\n",
      "Epoch 433/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5317 - accuracy: 0.7970 - val_loss: 0.6790 - val_accuracy: 0.7507\n",
      "Epoch 434/500\n",
      "132/132 [==============================] - 2s 11ms/step - loss: 0.4922 - accuracy: 0.8161 - val_loss: 0.6631 - val_accuracy: 0.7688\n",
      "Epoch 435/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5102 - accuracy: 0.8090 - val_loss: 0.6566 - val_accuracy: 0.7650\n",
      "Epoch 436/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.5228 - accuracy: 0.8124 - val_loss: 0.6696 - val_accuracy: 0.7593\n",
      "Epoch 437/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5150 - accuracy: 0.8092 - val_loss: 0.6716 - val_accuracy: 0.7564\n",
      "Epoch 438/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5106 - accuracy: 0.8152 - val_loss: 0.6646 - val_accuracy: 0.7650\n",
      "Epoch 439/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.4963 - accuracy: 0.8183 - val_loss: 0.6717 - val_accuracy: 0.7583\n",
      "Epoch 440/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5168 - accuracy: 0.8028 - val_loss: 0.6670 - val_accuracy: 0.7631\n",
      "Epoch 441/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5124 - accuracy: 0.8085 - val_loss: 0.6631 - val_accuracy: 0.7669\n",
      "Epoch 442/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4920 - accuracy: 0.8193 - val_loss: 0.6639 - val_accuracy: 0.7612\n",
      "Epoch 443/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5092 - accuracy: 0.8080 - val_loss: 0.6754 - val_accuracy: 0.7593\n",
      "Epoch 444/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4984 - accuracy: 0.8166 - val_loss: 0.6619 - val_accuracy: 0.7593\n",
      "Epoch 445/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5149 - accuracy: 0.8004 - val_loss: 0.6597 - val_accuracy: 0.7640\n",
      "Epoch 446/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4899 - accuracy: 0.8234 - val_loss: 0.6657 - val_accuracy: 0.7697\n",
      "Epoch 447/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5206 - accuracy: 0.8065 - val_loss: 0.6814 - val_accuracy: 0.7526\n",
      "Epoch 448/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4918 - accuracy: 0.8068 - val_loss: 0.6693 - val_accuracy: 0.7621\n",
      "Epoch 449/500\n",
      "132/132 [==============================] - 2s 11ms/step - loss: 0.5064 - accuracy: 0.8082 - val_loss: 0.6615 - val_accuracy: 0.7621\n",
      "Epoch 450/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.4838 - accuracy: 0.8130 - val_loss: 0.6618 - val_accuracy: 0.7669\n",
      "Epoch 451/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5314 - accuracy: 0.8025 - val_loss: 0.6630 - val_accuracy: 0.7697\n",
      "Epoch 452/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4922 - accuracy: 0.8182 - val_loss: 0.6546 - val_accuracy: 0.7650\n",
      "Epoch 453/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4792 - accuracy: 0.8294 - val_loss: 0.6651 - val_accuracy: 0.7564\n",
      "Epoch 454/500\n",
      "132/132 [==============================] - 2s 11ms/step - loss: 0.5035 - accuracy: 0.8138 - val_loss: 0.6756 - val_accuracy: 0.7602\n",
      "Epoch 455/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.4997 - accuracy: 0.8193 - val_loss: 0.6527 - val_accuracy: 0.7707\n",
      "Epoch 456/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5067 - accuracy: 0.8146 - val_loss: 0.6585 - val_accuracy: 0.7707\n",
      "Epoch 457/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.4910 - accuracy: 0.8174 - val_loss: 0.6554 - val_accuracy: 0.7707\n",
      "Epoch 458/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5075 - accuracy: 0.8140 - val_loss: 0.6690 - val_accuracy: 0.7555\n",
      "Epoch 459/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5161 - accuracy: 0.8041 - val_loss: 0.6611 - val_accuracy: 0.7678\n",
      "Epoch 460/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4782 - accuracy: 0.8255 - val_loss: 0.6522 - val_accuracy: 0.7640\n",
      "Epoch 461/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4912 - accuracy: 0.8179 - val_loss: 0.6605 - val_accuracy: 0.7697\n",
      "Epoch 462/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.5248 - accuracy: 0.8001 - val_loss: 0.6597 - val_accuracy: 0.7678\n",
      "Epoch 463/500\n",
      "132/132 [==============================] - 2s 11ms/step - loss: 0.5177 - accuracy: 0.8085 - val_loss: 0.6612 - val_accuracy: 0.7716\n",
      "Epoch 464/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.5068 - accuracy: 0.8136 - val_loss: 0.6565 - val_accuracy: 0.7650\n",
      "Epoch 465/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.4926 - accuracy: 0.8239 - val_loss: 0.6595 - val_accuracy: 0.7564\n",
      "Epoch 466/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4810 - accuracy: 0.8233 - val_loss: 0.6570 - val_accuracy: 0.7669\n",
      "Epoch 467/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4852 - accuracy: 0.8146 - val_loss: 0.6538 - val_accuracy: 0.7678\n",
      "Epoch 468/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.4911 - accuracy: 0.8205 - val_loss: 0.6540 - val_accuracy: 0.7726\n",
      "Epoch 469/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4832 - accuracy: 0.8244 - val_loss: 0.6493 - val_accuracy: 0.7735\n",
      "Epoch 470/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.4849 - accuracy: 0.8169 - val_loss: 0.6687 - val_accuracy: 0.7574\n",
      "Epoch 471/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5133 - accuracy: 0.8133 - val_loss: 0.6599 - val_accuracy: 0.7669\n",
      "Epoch 472/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5022 - accuracy: 0.8147 - val_loss: 0.6490 - val_accuracy: 0.7735\n",
      "Epoch 473/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4759 - accuracy: 0.8197 - val_loss: 0.6520 - val_accuracy: 0.7678\n",
      "Epoch 474/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4854 - accuracy: 0.8225 - val_loss: 0.6645 - val_accuracy: 0.7555\n",
      "Epoch 475/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4949 - accuracy: 0.8150 - val_loss: 0.6558 - val_accuracy: 0.7669\n",
      "Epoch 476/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4785 - accuracy: 0.8263 - val_loss: 0.6521 - val_accuracy: 0.7669\n",
      "Epoch 477/500\n",
      "132/132 [==============================] - 2s 11ms/step - loss: 0.4853 - accuracy: 0.8181 - val_loss: 0.6551 - val_accuracy: 0.7612\n",
      "Epoch 478/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4848 - accuracy: 0.8180 - val_loss: 0.6595 - val_accuracy: 0.7650\n",
      "Epoch 479/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.5110 - accuracy: 0.8137 - val_loss: 0.6577 - val_accuracy: 0.7697\n",
      "Epoch 480/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4702 - accuracy: 0.8297 - val_loss: 0.6572 - val_accuracy: 0.7602\n",
      "Epoch 481/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4773 - accuracy: 0.8246 - val_loss: 0.6536 - val_accuracy: 0.7678\n",
      "Epoch 482/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4918 - accuracy: 0.8151 - val_loss: 0.6485 - val_accuracy: 0.7678\n",
      "Epoch 483/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4972 - accuracy: 0.8196 - val_loss: 0.6382 - val_accuracy: 0.7735\n",
      "Epoch 484/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4528 - accuracy: 0.8346 - val_loss: 0.6465 - val_accuracy: 0.7688\n",
      "Epoch 485/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4728 - accuracy: 0.8237 - val_loss: 0.6491 - val_accuracy: 0.7640\n",
      "Epoch 486/500\n",
      "132/132 [==============================] - 2s 11ms/step - loss: 0.4971 - accuracy: 0.8155 - val_loss: 0.6443 - val_accuracy: 0.7764\n",
      "Epoch 487/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5071 - accuracy: 0.8091 - val_loss: 0.6424 - val_accuracy: 0.7745\n",
      "Epoch 488/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4937 - accuracy: 0.8258 - val_loss: 0.6515 - val_accuracy: 0.7631\n",
      "Epoch 489/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.4953 - accuracy: 0.8210 - val_loss: 0.6516 - val_accuracy: 0.7650\n",
      "Epoch 490/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4771 - accuracy: 0.8231 - val_loss: 0.6480 - val_accuracy: 0.7678\n",
      "Epoch 491/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.4959 - accuracy: 0.8156 - val_loss: 0.6519 - val_accuracy: 0.7726\n",
      "Epoch 492/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.4768 - accuracy: 0.8256 - val_loss: 0.6633 - val_accuracy: 0.7678\n",
      "Epoch 493/500\n",
      "132/132 [==============================] - 1s 10ms/step - loss: 0.4653 - accuracy: 0.8303 - val_loss: 0.6438 - val_accuracy: 0.7659\n",
      "Epoch 494/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4765 - accuracy: 0.8204 - val_loss: 0.6425 - val_accuracy: 0.7716\n",
      "Epoch 495/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4610 - accuracy: 0.8367 - val_loss: 0.6412 - val_accuracy: 0.7774\n",
      "Epoch 496/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.5022 - accuracy: 0.8089 - val_loss: 0.6486 - val_accuracy: 0.7650\n",
      "Epoch 497/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4691 - accuracy: 0.8317 - val_loss: 0.6478 - val_accuracy: 0.7650\n",
      "Epoch 498/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.4720 - accuracy: 0.8257 - val_loss: 0.6505 - val_accuracy: 0.7688\n",
      "Epoch 499/500\n",
      "132/132 [==============================] - 2s 12ms/step - loss: 0.4854 - accuracy: 0.8246 - val_loss: 0.6454 - val_accuracy: 0.7716\n",
      "Epoch 500/500\n",
      "132/132 [==============================] - 1s 11ms/step - loss: 0.4799 - accuracy: 0.8257 - val_loss: 0.6397 - val_accuracy: 0.7793\n"
     ]
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "#Adding the input LSTM network layer\n",
    "classifier.add(LSTM(128, input_shape=x_traincnn.shape[1:], return_sequences=True))\n",
    "classifier.add(Dropout(0.1))\n",
    "classifier.add(LSTM(128))\n",
    "classifier.add(Dropout(0.1))\n",
    "classifier.add(Dense(64)) \n",
    "classifier.add(Dense(8, activation='softmax')) \n",
    "#Compiling the network\n",
    "opt = optimizers.RMSprop(learning_rate=0.00001)\n",
    "classifier.compile(loss='sparse_categorical_crossentropy',optimizer=opt,metrics=['accuracy'] )\n",
    "\n",
    "#Fitting the data to the model\n",
    "lstmhist = classifier.fit(x_traincnn,y_train,epochs=500,validation_data=(x_testcnn, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "en6tGuIyRx0h",
    "outputId": "bb27035d-c30f-4e84-ce51-5c4114358537"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7859921273349321, 0.7792578496669839, 0.780278098608173, None)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = np.argmax(classifier.predict(x_testcnn),axis=-1)\n",
    "print(precision_recall_fscore_support(y_test,y_pred,average=\"weighted\"))\n",
    "\n",
    "# Başarı oranımızın grafiği\n",
    "\n",
    "plt.plot(lstmhist.history['accuracy'])\n",
    "plt.plot(lstmhist.history['val_accuracy'])\n",
    "plt.title('LSTM Başarı Oranı')\n",
    "plt.ylabel('Başarı')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.savefig('accuracyLSTM.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOX10MNZuIaq"
   },
   "source": [
    "### CoLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-T75QQUA75I4",
    "outputId": "991d5e74-22c2-4118-a519-4de3a9b78c82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 40, 128)           512       \n",
      "_________________________________________________________________\n",
      "B.Norm.1 (BatchNormalization (None, 40, 128)           512       \n",
      "_________________________________________________________________\n",
      "ReLU-1 (Activation)          (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 40, 256)           98560     \n",
      "_________________________________________________________________\n",
      "B.Norm.2 (BatchNormalization (None, 40, 256)           1024      \n",
      "_________________________________________________________________\n",
      "ReLU-2 (Activation)          (None, 40, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 40, 256)           196864    \n",
      "_________________________________________________________________\n",
      "B.Norm.3 (BatchNormalization (None, 40, 256)           1024      \n",
      "_________________________________________________________________\n",
      "ReLU-3 (Activation)          (None, 40, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 40, 512)           393728    \n",
      "_________________________________________________________________\n",
      "B.Norm.4 (BatchNormalization (None, 40, 512)           2048      \n",
      "_________________________________________________________________\n",
      "ReLU-4 (Activation)          (None, 40, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 40, 256)           787456    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 40, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 40, 128)           197120    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 40, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 5120)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 40968     \n",
      "=================================================================\n",
      "Total params: 1,719,816\n",
      "Trainable params: 1,717,512\n",
      "Non-trainable params: 2,304\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 11s 28ms/step - loss: 1.6377 - accuracy: 0.4171 - val_loss: 1.4984 - val_accuracy: 0.4900\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.9273 - accuracy: 0.6628 - val_loss: 0.8693 - val_accuracy: 0.6755\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 2s 19ms/step - loss: 0.8031 - accuracy: 0.7043 - val_loss: 0.6849 - val_accuracy: 0.7460\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 2s 19ms/step - loss: 0.6790 - accuracy: 0.7506 - val_loss: 0.6508 - val_accuracy: 0.7507\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.6609 - accuracy: 0.7498 - val_loss: 0.7653 - val_accuracy: 0.7241\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.6379 - accuracy: 0.7698 - val_loss: 0.6488 - val_accuracy: 0.7602\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 2s 19ms/step - loss: 0.5919 - accuracy: 0.7845 - val_loss: 0.8173 - val_accuracy: 0.7241\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.5539 - accuracy: 0.7999 - val_loss: 0.6414 - val_accuracy: 0.7697\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 2s 19ms/step - loss: 0.5486 - accuracy: 0.8011 - val_loss: 0.6357 - val_accuracy: 0.7659\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.5460 - accuracy: 0.7902 - val_loss: 0.5711 - val_accuracy: 0.7973\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.5127 - accuracy: 0.8173 - val_loss: 0.6343 - val_accuracy: 0.7688\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.4919 - accuracy: 0.8242 - val_loss: 0.6397 - val_accuracy: 0.7821\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.4587 - accuracy: 0.8266 - val_loss: 0.6050 - val_accuracy: 0.7926\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.4452 - accuracy: 0.8316 - val_loss: 0.5912 - val_accuracy: 0.7878\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 5.999999848427251e-05.\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.3960 - accuracy: 0.8597 - val_loss: 0.5209 - val_accuracy: 0.8192\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 2s 19ms/step - loss: 0.3519 - accuracy: 0.8703 - val_loss: 0.5841 - val_accuracy: 0.8030\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.3034 - accuracy: 0.8869 - val_loss: 0.5563 - val_accuracy: 0.8107\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.3180 - accuracy: 0.8835 - val_loss: 0.4861 - val_accuracy: 0.8202\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.2973 - accuracy: 0.8877 - val_loss: 0.4874 - val_accuracy: 0.8287\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.2716 - accuracy: 0.9058 - val_loss: 0.5021 - val_accuracy: 0.8430\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.2611 - accuracy: 0.9020 - val_loss: 0.5665 - val_accuracy: 0.8173\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.2803 - accuracy: 0.8950 - val_loss: 0.5279 - val_accuracy: 0.8278\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.599999909056351e-05.\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.2108 - accuracy: 0.9234 - val_loss: 0.4595 - val_accuracy: 0.8449\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.1719 - accuracy: 0.9448 - val_loss: 0.4693 - val_accuracy: 0.8525\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.1623 - accuracy: 0.9444 - val_loss: 0.4611 - val_accuracy: 0.8506\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 3s 20ms/step - loss: 0.1503 - accuracy: 0.9517 - val_loss: 0.5714 - val_accuracy: 0.8363\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.1517 - accuracy: 0.9504 - val_loss: 0.4752 - val_accuracy: 0.8421\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 2.1599998581223188e-05.\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.1176 - accuracy: 0.9681 - val_loss: 0.4567 - val_accuracy: 0.8601\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 2s 19ms/step - loss: 0.0960 - accuracy: 0.9724 - val_loss: 0.4678 - val_accuracy: 0.8601\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.0880 - accuracy: 0.9769 - val_loss: 0.5009 - val_accuracy: 0.8611\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.0825 - accuracy: 0.9797 - val_loss: 0.4981 - val_accuracy: 0.8525\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.0769 - accuracy: 0.9785 - val_loss: 0.4807 - val_accuracy: 0.8611\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.2959999367012642e-05.\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 2s 19ms/step - loss: 0.0799 - accuracy: 0.9792 - val_loss: 0.4711 - val_accuracy: 0.8611\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.0557 - accuracy: 0.9893 - val_loss: 0.4838 - val_accuracy: 0.8639\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.0555 - accuracy: 0.9849 - val_loss: 0.4735 - val_accuracy: 0.8620\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.0639 - accuracy: 0.9862 - val_loss: 0.4812 - val_accuracy: 0.8563\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 7.775999620207585e-06.\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 2s 19ms/step - loss: 0.0445 - accuracy: 0.9947 - val_loss: 0.4750 - val_accuracy: 0.8687\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.0467 - accuracy: 0.9907 - val_loss: 0.4855 - val_accuracy: 0.8668\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 2s 19ms/step - loss: 0.0415 - accuracy: 0.9939 - val_loss: 0.4836 - val_accuracy: 0.8735\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.0429 - accuracy: 0.9941 - val_loss: 0.4926 - val_accuracy: 0.8658\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 4.665599772124551e-06.\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.0380 - accuracy: 0.9955 - val_loss: 0.4899 - val_accuracy: 0.8677\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.0330 - accuracy: 0.9962 - val_loss: 0.4865 - val_accuracy: 0.8639\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.0362 - accuracy: 0.9952 - val_loss: 0.4942 - val_accuracy: 0.8677\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.0311 - accuracy: 0.9969 - val_loss: 0.4901 - val_accuracy: 0.8668\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 2.7993597541353666e-06.\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.0299 - accuracy: 0.9970 - val_loss: 0.4914 - val_accuracy: 0.8677\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.0320 - accuracy: 0.9975 - val_loss: 0.4903 - val_accuracy: 0.8696\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.0342 - accuracy: 0.9956 - val_loss: 0.4927 - val_accuracy: 0.8696\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.0317 - accuracy: 0.9967 - val_loss: 0.4941 - val_accuracy: 0.8677\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.6796157979115377e-06.\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.0331 - accuracy: 0.9966 - val_loss: 0.4936 - val_accuracy: 0.8706\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 2s 19ms/step - loss: 0.0326 - accuracy: 0.9965 - val_loss: 0.4955 - val_accuracy: 0.8677\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=128,kernel_size=3,input_shape=x_traincnn.shape[1:],padding='same'))\n",
    "model.add(BatchNormalization(name=\"B.Norm.1\"))\n",
    "model.add(Activation('relu',name=\"ReLU-1\"))\n",
    "model.add(Conv1D(filters=256,kernel_size=3,padding='same'))\n",
    "model.add(BatchNormalization(name=\"B.Norm.2\"))\n",
    "model.add(Activation('relu',name=\"ReLU-2\"))\n",
    "model.add(Conv1D(filters=256,kernel_size=3,padding='same'))\n",
    "model.add(BatchNormalization(name=\"B.Norm.3\"))\n",
    "model.add(Activation('relu',name=\"ReLU-3\"))\n",
    "model.add(Conv1D(filters=512,kernel_size=3,padding='same'))\n",
    "model.add(BatchNormalization(name=\"B.Norm.4\"))\n",
    "model.add(Activation('relu',name=\"ReLU-4\"))\n",
    "\n",
    "model.add(LSTM(256,return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(128,return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "#Compiling the network\n",
    "opt = AdaBound(learning_rate=1e-4, final_lr=0.1)\n",
    "model.compile(optimizer=opt, loss=keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "#Fitting the data to the model\n",
    "model.summary()\n",
    "\n",
    "num_epochs = 50\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.6, patience=4, min_lr=0.000001, verbose=1)\n",
    "cnnhistory=model.fit(x_traincnn, y_train, epochs=num_epochs,validation_data=(x_testcnn, y_test),callbacks=[lr_reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g93ERUGYukAc",
    "outputId": "af7a0a42-3053-4275-90fb-536cfd19fa05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8677450047573739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8698254329428383, 0.8677450047573739, 0.8682402982028936, None)"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(x_testcnn),axis=-1)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "#85.71 128 256 256 / 3 all / lr 1.4\n",
    "precision_recall_fscore_support(y_test,y_pred,average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "cYdzfnumuIat",
    "outputId": "b8224711-bcde-4970-81d8-2c583a1352c1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss oranımızın grafiği\n",
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('CNN+LSTM Loss Oranı')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.savefig('loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "LOCs65J3uIau",
    "outputId": "09237e10-f7b9-46d8-9db5-496ba19a65eb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Başarı oranımızın grafiği\n",
    "plt.plot(cnnhistory.history['accuracy'])\n",
    "plt.plot(cnnhistory.history['val_accuracy'])\n",
    "plt.title('CNN+LSTM Başarı Oranı')\n",
    "plt.ylabel('Başarı')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.savefig('accuracy.png')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "iWWrGaRbuIau",
    "nv16gJaluIav",
    "5g2wnOIduIaw",
    "EFQWpH1uuIaw",
    "qc4orAAWuIax"
   ],
   "name": "deneme.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "4a2e806b1a5243b0af361778732f137c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6eab77adf1f542ab9c22d76a63251f33": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "83ad67d5c119441dbedf53f234bebdf5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ceb6e7edec9463ab6192d10902c5c7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83ad67d5c119441dbedf53f234bebdf5",
      "placeholder": "​",
      "style": "IPY_MODEL_6eab77adf1f542ab9c22d76a63251f33",
      "value": " 517/5252 [04:26&lt;38:20,  2.06it/s]"
     }
    },
    "9e0688ef13f745f7ad1bf027ddfed2de": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf80a04fdda34d62a507291fa84a521e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d153754947f0471391e6be012b07c703": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d292c824d8c74fbdac065af0a18f6a7b",
       "IPY_MODEL_9ceb6e7edec9463ab6192d10902c5c7b"
      ],
      "layout": "IPY_MODEL_9e0688ef13f745f7ad1bf027ddfed2de"
     }
    },
    "d292c824d8c74fbdac065af0a18f6a7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": " 10%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf80a04fdda34d62a507291fa84a521e",
      "max": 5252,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4a2e806b1a5243b0af361778732f137c",
      "value": 517
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
